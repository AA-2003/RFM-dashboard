import streamlit as st
import polars as pl
import pandas as pd
from utils.load_data import load_contacts, load_deals, load_products, insert_rfm
from utils.logger import logger
from utils.custom_css import apply_custom_css
from utils.auth import login
from utils.rfm_calculator import extract_vip_status, extract_blacklist_status, \
    calculate_rfm, normalize_rfm, rfm_segmentation
from utils.constants import DEALID, DEALSTATUS, CUSTOMERID, CUSTOMERNAME, CUSTOMERPHONE, DEALDONEDATE, DEALCREATEDDATE, NIGHTS, DEALVALUE, PRODUCTID, PRODUCTTITLE, COMPLEX
from utils.funcs import get_first_successful_deal_date_for_customers

# Constants
DATA_REFRESH_DAYS = 7   

@st.cache_data(ttl=600, show_spinner=False)
def update_data():
    """Background function to update data. Only one update at a time."""
    try:
        logger.info("Starting background data update")
        st.session_state.deals = load_deals()
        st.session_state.products = load_products()
        st.session_state.deals = load_contacts()

        logger.info(f"Successfully updated data")
    except Exception as e:
        logger.error(f"Error during background data update: {str(e)}")

@st.cache_data(ttl=600, show_spinner=False)
def convert_to_nights(val):
    """Convert Persian text or numeric to integer nights."""
    if pd.isna(val):
        return None
    val = str(val).strip().replace("Ø´Ø¨", "").replace(" ", "")
    mapping = {
        "ÛŒÚ©": 1,
        "Ø¯Ùˆ": 2,
        "Ø³Ù‡": 3,
        "Ú†Ù‡Ø§Ø±": 4,
        "Ù¾Ù†Ø¬": 5,
        "Ø´Ø´": 6,
        "Ù‡ÙØª": 7,
        "Ù‡Ø´Øª": 8,
        "Ù†Ù‡": 9,
        "Ø¯Ù‡": 10,
    }
    return mapping.get(val, pd.to_numeric(val, errors="coerce"))


@st.cache_data(ttl=600, show_spinner=False)
def map_complex(name):
    name = str(name) if name is not None else ''
    if not name or name.lower() == 'nan':
        return ''

    if 'Ù…ÛŒØ±Ø¯Ø§Ù…Ø§Ø¯' in name:
        return 'Ù…ÛŒØ±Ø¯Ø§Ù…Ø§Ø¯'
    elif 'ÙˆÛŒÙ„Ø§' in name or 'Ù†Ø¬Ø§Øªâ€ŒØ§Ù„Ù„Ù‡ÛŒ' in name:
        return 'ÙˆÛŒÙ„Ø§'
    elif 'Ø¬Ø±Ø¯Ù†' in name:
        return 'Ø¬Ø±Ø¯Ù†'
    elif 'ØªØ±Ù†Ø¬' in name:
        return 'ØªØ±Ù†Ø¬'
    elif 'Ú¯Ø§Ù†Ø¯ÛŒ' in name:
        return 'Ú¯Ø§Ù†Ø¯ÛŒ'
    elif 'Ù†ÙˆÙÙ„' in name:
        return 'Ù†ÙˆÙÙ„'
    elif 'Ù¾Ø§Ø³Ø¯Ø§Ø±Ø§Ù†' in name or 'Ù¾Ø§Ø³Ø¯Ø°Ø§Ø±Ø§Ù†' in name:
        return 'Ù¾Ø§Ø³Ø¯Ø§Ø±Ø§Ù†'
    elif 'Ù…ØµÙ„ÛŒ' in name or 'Ù†ÛŒÙ„ÙˆÙØ±' in name:
        return 'Ù…ØµÙ„ÛŒ'
    elif 'Ú©Ø´Ø§ÙˆØ±Ø²' in name or 'Ú©Ø´Ø§ÙˆØ± Ø²' in name:
        return 'Ú©Ø´Ø§ÙˆØ±Ø²'
    elif 'Ø§Ø´Ø±ÙÛŒ' in name:
        return 'Ø§Ø´Ø±ÙÛŒ'
    elif 'Ù¾Ø§Ø±Ú© ÙˆÛŒ' in name or 'Ù¾Ø§Ø±Ú©â€ŒÙˆÛŒ' in name:
        return 'Ù¾Ø§Ø±Ú© ÙˆÛŒ'
    elif 'ÙˆÙ„ÛŒØ¹ØµØ±' in name:
        return 'ÙˆÙ„ÛŒØ¹ØµØ±'
    elif 'Ø§ÙˆÛŒÙ†' in name:
        return 'Ø§ÙˆÛŒÙ†'
    elif 'ÙˆÙ†Ú©' in name:
        return 'ÙˆÙ†Ú©'
    elif 'Ø¬Ù…Ù‡ÙˆØ±ÛŒ' in name or 'Ø¬Ù…ÙˆØ±ÛŒ' in name:
        return 'Ø¬Ù…Ù‡ÙˆØ±ÛŒ'
    elif 'ÙˆÙ„Ù†Ø¬Ú©' in name:
        return 'ÙˆÙ„Ù†Ø¬Ú©'
    elif 'Ø¨Ù‡Ø´ØªÛŒ' in name:
        return 'Ø¨Ù‡Ø´ØªÛŒ'
    elif 'Ù…Ø±Ø²Ø¯Ø§Ø±Ø§Ù†' in name or 'Ù…Ø±Ø²Ø±Ø¯Ø§Ø±Ø§Ù†' in name:
        return 'Ù…Ø±Ø²Ø¯Ø§Ø±Ø§Ù†'
    elif 'Ú©ÙˆØ±ÙˆØ´' in name:
        return 'Ú©ÙˆØ±ÙˆØ´'
    elif 'Ø¯Ù„Ú†Ù‡' in name:
        return 'Ø¯Ù„Ú†Ù‡'
    elif 'Ø´Ø±ÛŒØ¹ØªÛŒ' in name:
        return 'Ø´Ø±ÛŒØ¹ØªÛŒ'
    else:
        return 'Ù†Ø§Ù…Ø´Ø®Øµ'
    

@st.cache_data(ttl=600, show_spinner=False)
def preprocess_data(data: pd.DataFrame, products: pd.DataFrame, contacts: pd.DataFrame) -> pd.DataFrame:
    if data is None or data.empty:
        return pd.DataFrame()
    
    # map products and customer names
    product_map = products.drop_duplicates(subset='ProductCode').set_index('ProductCode')['ProductName']
    customer_map = contacts.drop_duplicates(subset='Customer_ID').set_index('Customer_ID')['DisplayName']

    data[PRODUCTTITLE] = data[PRODUCTID].map(product_map)
    data[CUSTOMERNAME] = data[CUSTOMERID].map(customer_map)

    data = data[data[CUSTOMERNAME].notna()].copy()
    data[COMPLEX] = data[PRODUCTTITLE].map(map_complex)

    data.loc[:, 'BlackList Status'] = extract_blacklist_status(data.get(CUSTOMERNAME, ''))
    data.loc[:, 'VIP Status'] = extract_vip_status(data.get(CUSTOMERNAME, ''))
    data = data[~data[DEALDONEDATE].isna()].copy()
    data = data[
        (~data[PRODUCTTITLE]
        .str.contains(r'Ø®ÙˆØ¯Ø±Ùˆ|ØµØ¨Ø­Ø§Ù†Ù‡|Ù†ÙØ± Ø§Ø¶Ø§ÙÙ‡', regex=True, na=False))
    ]
    data["nights"] = data[NIGHTS].apply(convert_to_nights).astype(float)
    data[DEALDONEDATE] = pd.to_datetime(data[DEALDONEDATE])
    data[DEALVALUE] = data[DEALVALUE] / 10
    st.session_state.first_deal_date_by_customer = get_first_successful_deal_date_for_customers(data)
    return data


@st.cache_data(ttl=10, show_spinner=False)
def rfm_calculation_cache(data):
    """Calculate RFM metrics."""
    try:
        rfm_data = rfm_segmentation(calculate_rfm(data))
        norm = normalize_rfm(rfm_data)
        if rfm_data is not None:
            return rfm_data, norm
        else:
            st.error("Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ RFM")
            return None
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ RFM : {e}")
        logger.error("Error in calcualting RFM:", e)
        return None

def main():
    """
    Main function that creates a Streamlit dashboard for Tehran Mobel sales analysis.
    """
    st.set_page_config(
        page_title="Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´ Ùˆ Ù…Ø´ØªØ±ÛŒ ØªÙ‡Ø±Ø§Ù† Ù…Ø¨Ù„Ù‡", 
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    apply_custom_css()
    st.title("Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´ Ùˆ Ù…Ø´ØªØ±ÛŒ ØªÙ‡Ø±Ø§Ù† Ù…Ø¨Ù„Ù‡")

    deals = load_deals()
    # st.write(deals)

    contacts = load_contacts()
    # st.write(contacts)

    products = load_products()
    # st.write(products)

    if 'auth' not in st.session_state or not st.session_state.auth:
        login()
    else:
        print("preprocess data and calculate RFM")
        # preprocess data and calculate RFM
        st.session_state.data = preprocess_data(deals, products, contacts)
        st.session_state.rfm_data, st.session_state.norm_rfm_data = rfm_calculation_cache(st.session_state.data)
        # save rfm
        insert_rfm(st.session_state.rfm_data)


        if deals is not None and not deals.empty:
            # Display data summary
            st.subheader("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
            col1, col2 = st.columns(2)

            with col1:
                st.metric("ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§", f"{len(st.session_state.data):,}")
            with col2:
                last_deal_date = st.session_state.data[DEALCREATEDDATE].max()
                st.metric("ØªØ§Ø±ÛŒØ® Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¹Ø§Ù…Ù„Ù‡", last_deal_date.strftime("%Y-%m-%d") if pd.notna(last_deal_date) else "Ù†Ø§Ù…Ø´Ø®Øµ")


if __name__ == "__main__":
    main()